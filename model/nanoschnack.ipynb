{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce047449aa6ea1b",
   "metadata": {},
   "source": [
    "# NanoSchnack Model\n",
    "\n",
    "## Setup\n",
    "\n",
    "- Install dependencies.\n",
    "- Verify that MPS is available (for Apple Silicon GPUs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe08928ac36354a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T17:27:20.105793Z",
     "start_time": "2025-12-20T17:27:20.072300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.backends.mps.is_available()\n",
    "torch.backends.mps.is_built()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291720d5f320a7a5",
   "metadata": {},
   "source": [
    "## Trying out MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "313e2a5486c901ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T17:27:23.193825Z",
     "start_time": "2025-12-20T17:27:23.180404Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "x = torch.randn(1024,1024, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f746ce3bad99a",
   "metadata": {},
   "source": [
    "## Loading a tokenizer with Hugging Face's tokenizer library\n",
    "\n",
    "Compare: https://github.com/huggingface/tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db31e04be138c071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T17:28:51.631656Z",
     "start_time": "2025-12-20T17:28:48.337996Z"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer_path = hf_hub_download(repo_id=\"openai-community/gpt2\", filename=\"tokenizer.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00a676960136ed2",
   "metadata": {},
   "source": [
    "## Testing the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "160288461bd092ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T17:31:32.304893Z",
     "start_time": "2025-12-20T17:31:32.234484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 2159, 0]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "output = tokenizer.encode(\"Hello, World!\")\n",
    "print(output.ids)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
